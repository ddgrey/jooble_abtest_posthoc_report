{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c32baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python-native\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Statistics\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import brunnermunzel\n",
    "import statsmodels.stats as sms\n",
    "from statsmodels.stats import proportion\n",
    "from statsmodels.stats import power as sms_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb43d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of A/B test result files\n",
    "path = Path(r'D:\\High-usage\\Data Science\\Data Analyst Path\\Projects\\Analytical Projects\\Jooble\\AB Test Results\\Data Prepared to Stat Testing')\n",
    "\n",
    "files = list(path.glob('*.csv'))\n",
    "if not files:\n",
    "        raise FileNotFoundError(\"No CSV files found in the directory.\")\n",
    "\n",
    "# Sorting files by date suffix (e.g. \"jooble_ml_ab_test_data_20250804\") and creation date\n",
    "sorted_dated_files = sorted(\n",
    "        files, \n",
    "        key=lambda f: (datetime.strptime(f.stem.split('_')[-1], '%Y%m%d'), datetime.fromtimestamp(f.stat().st_birthtime)), \n",
    "        reverse=True\n",
    ")\n",
    "\n",
    "# Fetching the most recent file path\n",
    "latest_file = sorted_dated_files[0]\n",
    "\n",
    "# Reading the latest A/B test result file\n",
    "ab_test = pd.read_csv(latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6eb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test functions (selected based on metric data type)\n",
    "\n",
    "def z_test_prop(variant_metric: pd.DataFrame) -> dict:\n",
    "    \"\"\"Z-test for proportions with a Confidence Interval, Effect Size (Cohen's h) and Power Analysis.\"\"\"\n",
    "        \n",
    "    metric_col_name = variant_metric.iloc[:, 1].name\n",
    "\n",
    "    # Calculating the number of successes and observations for each variant\n",
    "    sizes = variant_metric.groupby('variant').agg(\n",
    "        count=(metric_col_name, 'sum'),\n",
    "        nobs=(metric_col_name, 'size')\n",
    "    )\n",
    "\n",
    "    # Reorder so 'control' is first, regardless of treatment group name (e.g. 'treatment' vs. 'experiment')\n",
    "    indexes = sizes.index.tolist()\n",
    "    indexes.remove('control')\n",
    "    new_order = ['control'] + indexes\n",
    "    sizes = sizes.reindex(new_order)\n",
    "\n",
    "    count = sizes['count'].to_list()\n",
    "    nobs = sizes['nobs'].to_list()\n",
    "\n",
    "    # Performing the z-test for proportions\n",
    "    stat, pval = proportion.proportions_ztest(count, nobs, alternative='two-sided', prop_var=False)\n",
    "\n",
    "    # Calculating the confidence interval for the difference in proportions\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            ci_low, ci_upp = proportion.confint_proportions_2indep(\n",
    "                count[1], nobs[1], count[0], nobs[0], method='score' # score's root-finding algorithm may hit NaN if counts/proportions are at edge values (e.g., 0 or 1)\n",
    "                                                                     # the \"wald\" (inaccurate) or \"agresti-caffo\" (accurate) methods are more robust in edge cases\n",
    "            )\n",
    "    except ValueError:\n",
    "        # Fallback to 'agresti-caffo' if 'score' fails\n",
    "        ci_low, ci_upp = proportion.confint_proportions_2indep(\n",
    "            count[1], nobs[1], count[0], nobs[0], method='agresti-caffo'\n",
    "        )\n",
    "    \n",
    "    # Power analysis for the z-test\n",
    "    prop1 = count[0] / nobs[0] # control proportion\n",
    "    prop2 = count[1] / nobs[1] # treatment proportion\n",
    "    nobs1 = nobs[0]\n",
    "    nobs2 = nobs[1]\n",
    "    ratio = nobs2 / nobs1 # treatment to control ratio\n",
    "    alpha = 0.05\n",
    "    \n",
    "    # Calculate effect size (Cohen’s h)\n",
    "    # Cohen’s h measures the absolute difference between two proportions on an arcsine scale, not the relative difference; it's independent of sample size\n",
    "    # The larger the absolute difference between the proportions, the larger the effect size\n",
    "        # h ≈ 0.20 → Small effect (in practical terms)\n",
    "        # h ≈ 0.50 → Medium effect (in practical terms)\n",
    "        # h ≈ 0.80 → Large effect (in practical terms)\n",
    "    effect_size = proportion.proportion_effectsize(prop2, prop1)\n",
    "\n",
    "    # Calculate power of the test for detecting effect size with sample and alpha\n",
    "    power = sms_power.zt_ind_solve_power(effect_size=effect_size, nobs1=nobs1, alpha=alpha, ratio=ratio, alternative='two-sided')\n",
    "\n",
    "    return {\n",
    "        metric_col_name: [\n",
    "            # {'size': f'[c_{nobs[0]}, t_{nobs[1]}]'},\n",
    "            {'prop': f'[c_{prop1:.3f}, t_{prop2:.3f}]'},\n",
    "            {'rel_impr': f'{(prop2 - prop1) / prop1:.2%}'},\n",
    "            {'abs_impr': f'{prop2 - prop1:.2%}'},\n",
    "            {'pval': f'{pval:.4f}'}, \n",
    "            {'effect': f'{effect_size:.3f} ({'small' if abs(effect_size) < 0.20 else 'medium' if abs(effect_size) < 0.50 else 'large'})'},\n",
    "            {'ci_diff': f'[{ci_low:.3f}, {ci_upp:.3f}]'}, \n",
    "            {'power': f'{power:.3f}'},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def chi_squared_test(variant_metric: pd.DataFrame) -> dict:\n",
    "    \"\"\"Chi-squared test for categorical variables with an Effect Size (Cramer's V, Cohen's w) and Power Analysis.\"\"\"\n",
    "    \n",
    "    catvar_col_name = variant_metric.iloc[:, 1].name\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency = pd.crosstab(variant_metric['variant'], variant_metric[catvar_col_name])\n",
    "    k = contingency.shape[1] # number of categories\n",
    "    n = contingency.sum().sum() # total number of observations\n",
    "\n",
    "    # Perform the chi-squared test\n",
    "    chi2, pval, dof, expected = chi2_contingency(contingency)\n",
    "    \n",
    "    # Calculate effect size (Cramer's V)\n",
    "    # Cramer's V is a conservative measure of association between two categorical variables\n",
    "        # V ≈ 0.00-0.10 → Very small effect\n",
    "        # V ≈ 0.10-0.30 → Small effect\n",
    "        # V ≈ 0.30-0.50 → Medium effect\n",
    "        # V > 0.50 → Large effect\n",
    "    # *interpretation depends on the number of categories (k) – the more categories, the smaller the effect size for the same association strength\n",
    "    cramer_v = np.sqrt(chi2 / (n * min(contingency.shape) - 1))\n",
    "    \n",
    "    # Power analysis for the chi-squared test\n",
    "    cohen_w = cramer_v * np.sqrt(k - 1) # Cramer's V to Cohen's w conversion (used when calculating power)\n",
    "    alpha = 0.05\n",
    "    power = sms_power.GofChisquarePower().power(effect_size=cohen_w, nobs=n, alpha=alpha, n_bins=k)\n",
    "    \n",
    "    return {\n",
    "        catvar_col_name: [\n",
    "            {'categs': contingency.columns.tolist()},\n",
    "            # {'size': [contingency.sum().loc[dt] for dt in contingency.columns]},\n",
    "            {'prop': [f'{variant_metric[catvar_col_name].value_counts(normalize=True).loc[dt]:.1%}' for dt in contingency.columns]},\n",
    "            {'pval': f'{pval:.4f}'},\n",
    "            {'effect': f'{cramer_v:.3f} ({'negligible' if cramer_v < 0.10 else 'small' if cramer_v < 0.30 else 'medium' if cramer_v < 0.50 else 'large'})'},\n",
    "            {'power': f'{power:.3f}'}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def brunner_munzel_test(variant_metric: pd.DataFrame) -> dict:\n",
    "    \"\"\"Brunner-Munzel test for normal/non-normal distributions and equal/unequal variances with an Effect Size (Pest p*/Cliff's δ).\"\"\"\n",
    "    \n",
    "    metric_col_name = variant_metric.iloc[:, 1].name\n",
    "    \n",
    "    group1 = variant_metric[variant_metric['variant'] == 'control'][metric_col_name]\n",
    "    group2 = variant_metric[variant_metric['variant'] == 'treatment'][metric_col_name]\n",
    "    \n",
    "    # Performing the Brunner-Munzel test\n",
    "    stat, pval = brunnermunzel(group1, group2, alternative='two-sided')\n",
    "    \n",
    "    # Calculating the effect size (Pest/p*) as the probability of group2 being greater than group1 (stochastic superiority)\n",
    "    # Pest (i.e. probability estimation) serves as a rank-based probabilistic effect size that complements the Brunner-Munzel test\n",
    "        # Ranges from 0 to 1\n",
    "        # p* = 0.5 = no effect (called \"stochastic equality\") = the probability that Y is greater than X equals the probability that X is greater than Y.\n",
    "        # p* > 0.5 → values in Y tend to be larger than X\n",
    "        # p* < 0.5 → values in X tend to be larger than Y\n",
    "    nx, ny = len(group1), len(group2)\n",
    "    all_data = np.concatenate([group1, group2])\n",
    "    ranks = stats.rankdata(all_data)  # Automatically handles ties\n",
    "    rank_y = ranks[nx:]  # Ranks for group y\n",
    "    mean_rank_y = np.mean(rank_y)\n",
    "    effect_pest = (mean_rank_y - (ny + 1)/2) / nx # Derived from the original effect size (Pest) formula P(X<Y)+0.5⋅P(X=Y)\n",
    "\n",
    "    # Convert probability-based effect size (Pest) to straightforward Cliff’s Delta (-1 to 1 where 0 indicates no effect)\n",
    "        # Ranges from -1 to 1\n",
    "        # δ > 0 → Y tends to dominate X (e.g. +0.5 δ = 0.75 Pest)\n",
    "        # δ < 0 → X tends to dominate Y (e.g. -0.5 δ = 0.25 Pest)\n",
    "        # δ ≈ 0 → No dominance (0 = 0.5 Pest = stochastic equality)\n",
    "    effect_delta = 2 * effect_pest - 1 \n",
    "\n",
    "    return {\n",
    "        metric_col_name: [\n",
    "            # {'size': f'[c_{len(group1)}, t_{len(group2)}]'},\n",
    "            {'pval': f'{pval:.4f}'},\n",
    "            {'effect': f'{np.clip(effect_delta, -1.0, 1.0):.2f} ({'c over t' if abs(effect_delta) < 0 else 'no effect' if abs(effect_delta) == 0 else 't over c'})'},\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1e2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting primary and secondary metrics\n",
    "target_metrics_list = ab_test.columns[ab_test.columns.str.match(r'^(sm|pm)')].to_list()\n",
    "\n",
    "dtype_dstat_dict = {}\n",
    "# Calculating the type of statistical test for each metric based on its data type\n",
    "for metric in target_metrics_list:\n",
    "    variant_metric = ab_test[['variant', metric]]\n",
    "    # Checking if the metric is binary\n",
    "    if set(variant_metric[metric].dropna().unique()) <= set([0, 1]):\n",
    "        if 'binary' in dtype_dstat_dict:\n",
    "            dtype_dstat_dict['binary'].append(z_test_prop(variant_metric))\n",
    "        else:\n",
    "            dtype_dstat_dict['binary'] = [z_test_prop(variant_metric)]\n",
    "    # Checking if the metric is object/category\n",
    "    elif variant_metric[metric].dtype.kind in {'O', 'c'}:\n",
    "        if 'categorical' in dtype_dstat_dict:\n",
    "            dtype_dstat_dict['categorical'].append(chi_squared_test(variant_metric))\n",
    "        else:\n",
    "            dtype_dstat_dict['categorical'] = [chi_squared_test(variant_metric)]\n",
    "    # Checking if the metric is integer/float\n",
    "    elif variant_metric[metric].dtype.kind in {'i', 'f'}:\n",
    "        if 'numeric' in dtype_dstat_dict:\n",
    "            dtype_dstat_dict['numeric'].append(brunner_munzel_test(variant_metric))\n",
    "        else:\n",
    "            dtype_dstat_dict['numeric'] = [brunner_munzel_test(variant_metric)]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported data type for metric '{metric}': type({variant_metric[metric].dtype}), values({variant_metric[metric].unique()[:5]}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17a4eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Excel file 'ab_test_results_report.xlsx' with summary and detailed sheets has been created!\n",
      "Full path: d:\\High-usage\\Data Science\\Data Analyst Path\\Projects\\Analytical Projects\\Jooble\\AB Test Results\\ab_test_results_report.xlsx\n",
      "\n",
      "Excel file created:\n",
      "ab_test_results_report.xlsx - Multiple sheets with summary and detailed views\n"
     ]
    }
   ],
   "source": [
    "# Disassembling the dictionary into an Excel report file with proper formatting\n",
    "\n",
    "# Necessary libraries for Excel file creation\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side, Alignment\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import json\n",
    "\n",
    "def disassemble_dictionary_to_excel(data_dict, output_filename='ab_test_results.xlsx'):\n",
    "    \"\"\"\n",
    "    Disassembles a nested dictionary containing A/B test results and exports to Excel\n",
    "    with proper formatting and separate sections for each data type.\n",
    "    \n",
    "    Args:\n",
    "        data_dict (dict): The input dictionary with binary, numeric, and categorical data\n",
    "        output_filename (str): Name of the output Excel file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new workbook\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"AB Test Results\"\n",
    "    \n",
    "    # Define styles\n",
    "    header_font = Font(bold=True, size=12, color='FFFFFF')\n",
    "    header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "    \n",
    "    metric_font = Font(bold=True, size=11, color='FFFFFF')\n",
    "    metric_fill = PatternFill(start_color='4F81BD', end_color='4F81BD', fill_type='solid')\n",
    "    \n",
    "    stat_font = Font(size=10)\n",
    "    stat_fill = PatternFill(start_color='DCE6F1', end_color='DCE6F1', fill_type='solid')\n",
    "    \n",
    "    border = Border(\n",
    "        left=Side(style='thin'),\n",
    "        right=Side(style='thin'),\n",
    "        top=Side(style='thin'),\n",
    "        bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    center_alignment = Alignment(horizontal='center', vertical='center')\n",
    "    \n",
    "    current_row = 1\n",
    "    \n",
    "    # Process each data type (binary, numeric, categorical)\n",
    "    for data_type, metrics_list in data_dict.items():\n",
    "        # Add section header\n",
    "        section_header = f\"{data_type.upper()} VARIABLES\"\n",
    "        ws.cell(row=current_row, column=1, value=section_header)\n",
    "        ws.cell(row=current_row, column=1).font = header_font\n",
    "        ws.cell(row=current_row, column=1).fill = header_fill\n",
    "        ws.cell(row=current_row, column=1).border = border\n",
    "        ws.cell(row=current_row, column=1).alignment = center_alignment\n",
    "        \n",
    "        # Merge cells for section header (assuming 3 columns width)\n",
    "        ws.merge_cells(f'A{current_row}:C{current_row}')\n",
    "        current_row += 2\n",
    "        \n",
    "        # Process each metric in this data type\n",
    "        for metric_dict in metrics_list:\n",
    "            for metric_name, stats_list in metric_dict.items():\n",
    "                # Add metric name as table header\n",
    "                ws.cell(row=current_row, column=1, value=\"Metric\")\n",
    "                ws.cell(row=current_row, column=2, value=metric_name)\n",
    "                \n",
    "                # Style metric header\n",
    "                ws.cell(row=current_row, column=1).font = metric_font\n",
    "                ws.cell(row=current_row, column=1).fill = metric_fill\n",
    "                ws.cell(row=current_row, column=1).border = border\n",
    "                ws.cell(row=current_row, column=1).alignment = center_alignment\n",
    "                \n",
    "                ws.cell(row=current_row, column=2).font = metric_font\n",
    "                ws.cell(row=current_row, column=2).fill = metric_fill\n",
    "                ws.cell(row=current_row, column=2).border = border\n",
    "                ws.cell(row=current_row, column=2).alignment = center_alignment\n",
    "                \n",
    "                current_row += 1\n",
    "                \n",
    "                # Add statistics for this metric\n",
    "                for stat_dict in stats_list:\n",
    "                    for stat_name, stat_value in stat_dict.items():\n",
    "                        ws.cell(row=current_row, column=1, value=stat_name)\n",
    "                        ws.cell(row=current_row, column=2, value=stat_value)\n",
    "                        \n",
    "                        # Style statistics rows\n",
    "                        ws.cell(row=current_row, column=1).font = stat_font\n",
    "                        ws.cell(row=current_row, column=1).fill = stat_fill\n",
    "                        ws.cell(row=current_row, column=1).border = border\n",
    "                        ws.cell(row=current_row, column=1).alignment = center_alignment\n",
    "                        \n",
    "                        ws.cell(row=current_row, column=2).font = stat_font\n",
    "                        ws.cell(row=current_row, column=2).border = border\n",
    "                        \n",
    "                        current_row += 1\n",
    "                \n",
    "                # Add empty row between metrics for better readability\n",
    "                current_row += 1\n",
    "        \n",
    "        # Add extra space between sections\n",
    "        current_row += 2\n",
    "    \n",
    "    # Adjust column widths\n",
    "    ws.column_dimensions['A'].width = 25\n",
    "    ws.column_dimensions['B'].width = 30\n",
    "    ws.column_dimensions['C'].width = 15\n",
    "    \n",
    "    # Save the workbook\n",
    "    full_path = os.path.abspath(output_filename)\n",
    "    wb.save(output_filename)\n",
    "    print(f\"Excel file '{output_filename}' has been created successfully!\")\n",
    "    print(f\"Full path: {full_path}\")\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "def create_summary_sheet(data_dict, output_filename='ab_test_results_report.xlsx'):\n",
    "    \"\"\"\n",
    "    Creates an enhanced version with both detailed and summary sheets\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new workbook with summary\n",
    "    wb = Workbook()\n",
    "    \n",
    "    # Remove default sheet and create our sheets\n",
    "    wb.remove(wb.active)\n",
    "    summary_ws = wb.create_sheet(\"Summary\")\n",
    "    detailed_ws = wb.create_sheet(\"Detailed Results\")\n",
    "    \n",
    "    # Set Summary sheet tab color to green-grey\n",
    "    summary_ws.sheet_properties.tabColor = \"A8C090\"\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_data = []\n",
    "    \n",
    "    for data_type, metrics_list in data_dict.items():\n",
    "        for metric_dict in metrics_list:\n",
    "            for metric_name, stats_list in metric_dict.items():\n",
    "                row_data = {'Data Type': data_type.capitalize(), 'Metric': metric_name}\n",
    "                \n",
    "                # Extract key statistics\n",
    "                for stat_dict in stats_list:\n",
    "                    for stat_name, stat_value in stat_dict.items():\n",
    "                        row_data[stat_name] = stat_value\n",
    "                \n",
    "                summary_data.append(row_data)\n",
    "    \n",
    "    # Create DataFrame and write to summary sheet\n",
    "    if summary_data:\n",
    "        df_summary = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Write headers\n",
    "        headers = list(df_summary.columns)\n",
    "        for col_idx, header in enumerate(headers, 1):\n",
    "            cell = summary_ws.cell(row=1, column=col_idx, value=header)\n",
    "            cell.font = Font(bold=True, color='FFFFFF')\n",
    "            cell.fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "            cell.border = Border(\n",
    "                left=Side(style='thin'),\n",
    "                right=Side(style='thin'),\n",
    "                top=Side(style='thin'),\n",
    "                bottom=Side(style='thin')\n",
    "            )\n",
    "            cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        \n",
    "        # Write data\n",
    "        for row_idx, row in enumerate(df_summary.itertuples(index=False), 2):\n",
    "            for col_idx, value in enumerate(row, 1):\n",
    "                cell = summary_ws.cell(row=row_idx, column=col_idx, value=value)\n",
    "                cell.border = Border(\n",
    "                    left=Side(style='thin'),\n",
    "                    right=Side(style='thin'),\n",
    "                    top=Side(style='thin'),\n",
    "                    bottom=Side(style='thin')\n",
    "                )\n",
    "                if row_idx % 2 == 0:\n",
    "                    cell.fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        for column in summary_ws.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 30)\n",
    "            summary_ws.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "    # Now create the detailed sheet with the same formatting as before\n",
    "    current_row = 1\n",
    "    \n",
    "    # Define styles (same as before)\n",
    "    header_font = Font(bold=True, size=12, color='FFFFFF')\n",
    "    header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "    \n",
    "    metric_font = Font(bold=True, size=11, color='FFFFFF')\n",
    "    metric_fill = PatternFill(start_color='4F81BD', end_color='4F81BD', fill_type='solid')\n",
    "    \n",
    "    stat_font = Font(size=10)\n",
    "    stat_fill = PatternFill(start_color='DCE6F1', end_color='DCE6F1', fill_type='solid')\n",
    "    \n",
    "    border = Border(\n",
    "        left=Side(style='thin'),\n",
    "        right=Side(style='thin'),\n",
    "        top=Side(style='thin'),\n",
    "        bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    center_alignment = Alignment(horizontal='center', vertical='center')\n",
    "    \n",
    "    # Define test names for each data type\n",
    "    test_names = {\n",
    "        'binary': 'Z-test for proportions',\n",
    "        'categorical': 'Chi-squared test',\n",
    "        'numeric': 'Brunner-Munzel test'\n",
    "    }\n",
    "    \n",
    "    # Process each data type for detailed sheet\n",
    "    for data_type, metrics_list in data_dict.items():\n",
    "        # Add section header with test name\n",
    "        test_name = test_names.get(data_type, '')\n",
    "        section_header = f\"{data_type.upper()} VARIABLES ({test_name})\"\n",
    "        detailed_ws.cell(row=current_row, column=1, value=section_header)\n",
    "        detailed_ws.cell(row=current_row, column=1).font = header_font\n",
    "        detailed_ws.cell(row=current_row, column=1).fill = header_fill\n",
    "        detailed_ws.cell(row=current_row, column=1).border = border\n",
    "        detailed_ws.cell(row=current_row, column=1).alignment = center_alignment\n",
    "        \n",
    "        # Merge cells for section header\n",
    "        detailed_ws.merge_cells(f'A{current_row}:C{current_row}')\n",
    "        current_row += 2\n",
    "        \n",
    "        # Process each metric\n",
    "        for metric_dict in metrics_list:\n",
    "            for metric_name, stats_list in metric_dict.items():\n",
    "                # Add metric name as table header\n",
    "                detailed_ws.cell(row=current_row, column=1, value=\"Metric\")\n",
    "                detailed_ws.cell(row=current_row, column=2, value=metric_name)\n",
    "                \n",
    "                # Style metric header\n",
    "                detailed_ws.cell(row=current_row, column=1).font = metric_font\n",
    "                detailed_ws.cell(row=current_row, column=1).fill = metric_fill\n",
    "                detailed_ws.cell(row=current_row, column=1).border = border\n",
    "                detailed_ws.cell(row=current_row, column=1).alignment = center_alignment\n",
    "                \n",
    "                detailed_ws.cell(row=current_row, column=2).font = metric_font\n",
    "                detailed_ws.cell(row=current_row, column=2).fill = metric_fill\n",
    "                detailed_ws.cell(row=current_row, column=2).border = border\n",
    "                detailed_ws.cell(row=current_row, column=2).alignment = center_alignment\n",
    "                \n",
    "                current_row += 1\n",
    "                \n",
    "                # Add statistics\n",
    "                for stat_dict in stats_list:\n",
    "                    for stat_name, stat_value in stat_dict.items():\n",
    "                        detailed_ws.cell(row=current_row, column=1, value=stat_name)\n",
    "                        detailed_ws.cell(row=current_row, column=2, value=stat_value)\n",
    "                        \n",
    "                        # Style statistics rows\n",
    "                        detailed_ws.cell(row=current_row, column=1).font = stat_font\n",
    "                        detailed_ws.cell(row=current_row, column=1).fill = stat_fill\n",
    "                        detailed_ws.cell(row=current_row, column=1).border = border\n",
    "                        detailed_ws.cell(row=current_row, column=1).alignment = center_alignment\n",
    "                        \n",
    "                        detailed_ws.cell(row=current_row, column=2).font = stat_font\n",
    "                        detailed_ws.cell(row=current_row, column=2).border = border\n",
    "                        \n",
    "                        current_row += 1\n",
    "                \n",
    "                current_row += 1\n",
    "        \n",
    "        current_row += 2\n",
    "    \n",
    "    # Adjust column widths for detailed sheet\n",
    "    detailed_ws.column_dimensions['A'].width = 25\n",
    "    detailed_ws.column_dimensions['B'].width = 30\n",
    "    detailed_ws.column_dimensions['C'].width = 15\n",
    "    \n",
    "    # Save the workbook\n",
    "    full_path = os.path.abspath(output_filename)\n",
    "    wb.save(output_filename)\n",
    "    print(f\"Enhanced Excel file '{output_filename}' with summary and detailed sheets has been created!\")\n",
    "    print(f\"Full path: {full_path}\")\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data = dtype_dstat_dict\n",
    "    \n",
    "    # Create the detailed results Excel file\n",
    "    create_summary_sheet(data)\n",
    "    \n",
    "    print(\"\\nExcel file created:\")\n",
    "    print(\"ab_test_results_report.xlsx - Multiple sheets with summary and detailed views\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
